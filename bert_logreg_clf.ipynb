{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymorphy2[fast]\n",
    "!pip install -U pymorphy2-dicts-ru\n",
    "!pip install nltk\n",
    "!pip install transformers\n",
    "!pip install imblearn\n",
    "!pip install stanza\n",
    "!pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import codecs\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import stanza\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download(\"stopwords\")\n",
    "stanza.download('ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_state(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    print(f\"seed={seed} fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_name=\"test.csv\"):\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    print(f\"Unique dialogs: {df['dlg_id'].unique().shape[0]}\\n\")\n",
    "    print(f\"Misses:\\n{df.isna().sum()}\\n\")\n",
    "    print(f\"Column types:\\n{df.dtypes}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    def greeting_func(sentence):\n",
    "        for greeting in greetings_list:\n",
    "            if re.findall(greeting, sentence.lower()):\n",
    "                return 1\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    # role = {\n",
    "    #     \"client\": 0,\n",
    "    #     \"manager\": 1\n",
    "    # }\n",
    "    \n",
    "    greetings_list = [\n",
    "        \"доброе утро\"\n",
    "        \"добрый день\",\n",
    "        \"добрый вечер\",\n",
    "        \"здравствуйте\",\n",
    "        \"до свидания\",\n",
    "        \"меня зовут\",\n",
    "    ]\n",
    "    \n",
    "    df = data.copy()\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    ru_stopwords = stopwords.words(\"russian\")\n",
    "    digits = [str(i) for i in range(10)]\n",
    "    \n",
    "    # df[\"text\"] = df[\"text\"].apply(lambda sentences: \" \".join([morph.normal_forms(word)[0]\n",
    "    #                                   for word in sentences.split()\n",
    "    #                                   if (word not in ru_stopwords) and (word[0] not in digits)]))\n",
    "    # df[\"role\"] = df[\"role\"].apply(lambda person: role[person])\n",
    "    \n",
    "    df[\"text\"] = df[\"text\"].apply(lambda sentences: \" \".join([word for word in sentences.split()\n",
    "                                                              if (word[0]) not in digits]))\n",
    "    df[\"insight\"] = df[\"text\"].apply(lambda sentences: greeting_func(sentences))\n",
    "    \n",
    "    # X_train = df[(df[\"dlg_id\"] <= 3) & (df[\"role\"] == 1)]\n",
    "    # X_test = df[(4 <= df[\"dlg_id\"]) & (df[\"role\"] == 1)]\n",
    "    \n",
    "    # X_train = df[(df[\"dlg_id\"] <= 3)]\n",
    "    # X_test = df[(4 <= df[\"dlg_id\"])]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(X, Y, batch_size=1):\n",
    "    num_objects = X.shape[0]\n",
    "\n",
    "    indices = np.arange(num_objects)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for start in range(0, num_objects, batch_size):\n",
    "        end = min(start + batch_size, num_objects)\n",
    "        batch_idx = indices[start:end]\n",
    "\n",
    "        yield X[batch_idx], Y[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    embedding_corpus = []\n",
    "    \n",
    "    for replic in text:\n",
    "        t = tokenizer(replic, padding=True, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "        embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "        embeddings = torch.nn.functional.normalize(embeddings)\n",
    "        \n",
    "        embedding_corpus.append(embeddings[0].cpu().numpy())\n",
    "    \n",
    "    return torch.tensor((embedding_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nn_clf(in_feat, out_feat, classes=2):\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_feat, out_feat),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(out_feat),\n",
    "        nn.Linear(out_feat, out_feat),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(out_feat),\n",
    "        nn.Linear(out_feat, classes),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    return model, optimizer, criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, epochs=50, eval_every=10 , plot=True):\n",
    "    loss_history = []\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):  \n",
    "        for X, y in data_loader(train_set, train_labels, batch_size=train_set.shape[0]):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "        # print(f\"avg loss epoch: {loss_history[-1] / train_set.shape[0]}\")\n",
    "        \n",
    "        if (epoch + 1) % eval_every == 0:\n",
    "            model.eval()\n",
    "            \n",
    "            y_test_pred = model(test_set).argmax(axis=1)\n",
    "            y_train_pred = model(train_set).argmax(axis=1)\n",
    "            \n",
    "            print(f\"Epoch: {epoch + 1}\")\n",
    "            print(f\"Accuracy test: {accuracy_score(y_test_pred, test_labels)}\")\n",
    "            print(f\"Accuracy train: {accuracy_score(y_train_pred, train_labels)}\")\n",
    "            print()\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "    if plot: \n",
    "        plt.plot(np.arange(EPOCHS), loss_history)\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.title(\"loss history\")\n",
    "        plt.show()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(nn_model, clf, data, labels, report=True):\n",
    "    nn_model.eval()\n",
    "    \n",
    "    clf_pred = clf.predict(data)\n",
    "    one_class_pred = np.ones(shape=(labels.shape[0],))\n",
    "    zero_class_pred = np.zeros(shape=(labels.shape[0],))\n",
    "    nn_clf_pred = nn_model(data).detach().numpy().argmax(axis=1)\n",
    "    \n",
    "    nn_model.train()\n",
    "    \n",
    "    \n",
    "    if report:\n",
    "        print(f\"Neural Network clf accuracy: {accuracy_score(nn_clf_pred, labels)}\")\n",
    "        print(f\"Linear clf accuracy: {accuracy_score(clf_pred, labels)}\")\n",
    "        print(f\"0 class accuracy: {accuracy_score(zero_class_pred, labels)}\")\n",
    "        print(f\"1 class accuracy: {accuracy_score(one_class_pred, labels)}\\n\")\n",
    "        \n",
    "        print(\"Neural network clf report:\")\n",
    "        print(classification_report(labels, nn_clf_pred))\n",
    "        print()\n",
    "        \n",
    "        print(\"Logistic Regression report:\")\n",
    "        print(classification_report(labels, clf_pred))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict(text_corpus, bert, tokenizer, clf, neural_clf=True):\n",
    "    embedding = embed_bert_cls(text_corpus, bert, tokenizer)\n",
    "    \n",
    "    if neural_clf:\n",
    "        clf.eval()\n",
    "    \n",
    "        pred_class = clf(embedding).argmax(axis=1)\n",
    "    \n",
    "        clf.train()\n",
    "        \n",
    "    else:\n",
    "        pred_class = clf.predict(embedding)\n",
    "\n",
    "    print(f\"text: {text_corpus} - class: {pred_class}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(nn_model, default_model):\n",
    "    torch.save(nn_model.state_dict(), \"./models/nn_classifier.pt\")\n",
    "    pickle.dump(default_model, open(\"./models/logreg_classifier.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanza_nlp_ru(text):\n",
    "    nlp = stanza.Pipeline(lang='ru', processors='tokenize,ner')\n",
    "    doc = nlp(text)\n",
    "\n",
    "    print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=0 fixed\n"
     ]
    }
   ],
   "source": [
    "set_random_state(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique dialogs: 6\n",
      "\n",
      "Misses:\n",
      "dlg_id    0\n",
      "line_n    0\n",
      "role      0\n",
      "text      0\n",
      "dtype: int64\n",
      "\n",
      "Column types:\n",
      "dlg_id     int64\n",
      "line_n     int64\n",
      "role      object\n",
      "text      object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(480, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(file_name=\"./test_data/test.csv\")\n",
    "test_data = preprocess_data(df)\n",
    "\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pretrained rubert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubert, tokenizer = load_bert(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Test split + extracted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480, 5), torch.Size([480, 312]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = embed_bert_cls(test_data[\"text\"], rubert, tokenizer)\n",
    "test_labels = torch.tensor(test_data[\"insight\"].to_numpy(), dtype=torch.int64)\n",
    "\n",
    "\n",
    "test_data.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made Neural Network classifier and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "\n",
    "txt_file = codecs.open(\"./train_data/dialogues/dialogues.txt\", \"r\", \"utf_8_sig\" )\n",
    "counter = 0\n",
    "\n",
    "for line in txt_file:\n",
    "    correct_line = \" \".join(re.sub(\"[^А-Яа-я0-9]\", \" \", line).split())\n",
    "    \n",
    "    if counter == 100000:\n",
    "        break\n",
    "    \n",
    "    if correct_line:\n",
    "        train_set.append(correct_line)\n",
    "        counter += 1\n",
    "\n",
    "train_set = np.array(train_set)\n",
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame([])\n",
    "\n",
    "train_data[\"text\"] = train_set\n",
    "train_data = preprocess_data(train_data)\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100000, 312]), torch.Size([100000]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = embed_bert_cls(train_data[\"text\"], rubert, tokenizer)\n",
    "train_labels = torch.tensor(train_data[\"insight\"].to_numpy(), dtype=torch.int64)\n",
    "\n",
    "train_set.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = NearMiss()\n",
    "train_set, train_labels = nm.fit_resample(train_set, train_labels)\n",
    "\n",
    "train_set.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.tensor(train_set)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = train_set.shape[1]\n",
    "OUT_FEAT = 128\n",
    "CLASSES = 2\n",
    "\n",
    "\n",
    "nn_clf, optimizer, criterion = make_nn_clf(in_feat=FEATURES, out_feat=OUT_FEAT, classes=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50\n",
      "Accuracy test: 0.06458333333333334\n",
      "Accuracy train: 0.0485\n",
      "\n",
      "Epoch: 100\n",
      "Accuracy test: 0.9583333333333334\n",
      "Accuracy train: 0.96176\n",
      "\n",
      "Epoch: 150\n",
      "Accuracy test: 0.9604166666666667\n",
      "Accuracy train: 0.96207\n",
      "\n",
      "Epoch: 200\n",
      "Accuracy test: 0.9583333333333334\n",
      "Accuracy train: 0.96208\n",
      "\n",
      "Epoch: 250\n",
      "Accuracy test: 0.95625\n",
      "Accuracy train: 0.96209\n",
      "\n",
      "Epoch: 300\n",
      "Accuracy test: 0.95625\n",
      "Accuracy train: 0.96209\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAm2UlEQVR4nO3de3xddZ3u8c+zk6aXtOktaSm9kLQEaUFuhgoDXo4IVlTQARFGGXQc0Tkyo6MzRzjjoIMz53iZ46AznVFGmVFHrYx4qdcKCgoo0BRLpS2FEIpNW9r0fr8k+Z4/9krZDTtp0mZnZe/9vF+v/cpev/Vba39Xd5una/3WRRGBmZlZT5m0CzAzs+HJAWFmZnk5IMzMLC8HhJmZ5eWAMDOzvBwQZmaWlwPCSpqktZJeO0Sf9Z+S/r6P+XskzR6KWswGgwPCbIhExNiIaO2rj6RXS2obqprM+uKAMCshkirTrsFKhwPCyoakkZJul7Qhed0uaWQyr1bSDyXtkLRN0gOSMsm8j0haL2m3pDWSLunjYyZK+lHS9xFJc3I+PySdmry/XNKqpN96SX8lqRr4CXBycjhqj6STj1H3qyW1JTU+D/yHpCckvSnnc0dI2iLp3MH/U7VS5oCwcvI3wAXAOcDZwHzgo8m8DwNtQB0wFfjfQEh6CXATcH5EjANeB6zt4zOuBf4OmAi0AP/QS78vA+9N1nkm8IuI2Au8HtiQHI4aGxEbjlE3wEnAJOAU4Ebgq8A7cuZfDmyMiN/2UbfZizggrJy8HbgtIjZHRDvZX+TXJ/MOA9OAUyLicEQ8ENkblXUCI4F5kkZExNqIeKaPz/huRDwaER3A18n+Us/ncLLOmojYHhGPHWfdAF3AxyLiYETsB/4LuFxSTTL/euBrfazfLC8HhJWTk4HncqafS9oAPkP2f/w/k9Qq6WaAiGgBPgh8HNgsaZGkk+nd8znv9wFje+l3Fdn/2T8n6ZeSLjzOugHaI+JA90Sy1/EQcJWkCWT3Sr7ex/rN8nJAWDnZQPYwTLdZSRsRsTsiPhwRs4ErgA91jzVExDci4uJk2QA+daKFRMTSiLgSmAJ8D7ire9ZA6u5jma+QPcz0VuA3EbH+RGu28uOAsHLyTeCjkuok1QK3kj0cg6Q3SjpVkoCdZA8tdUl6iaTXJIPCB4D9ZA/pHDdJVZLeLml8RBwGduWscxMwWdL4/tTdh+8B5wEfIDsmYTZgDggrJ38PNAMrgN8BjyVtAI3AvcAe4DfAv0bEfWTHHz4JbCF7+GgKcMsg1HI9sFbSLuB9ZMcZiIgnyQZCa3JG1cnHqDuvZCzibqAB+M4g1GtlSH5gkFlpknQrcFpEvOOYnc3y8EU1ZiVI0iTg3Rx9tpPZgPgQk1mJkfQeYB3wk4j4Vdr1WPHyISYzM8vLexBmZpZXyYxB1NbWRn19fdplmJkVlWXLlm2JiLp880omIOrr62lubk67DDOzoiLpud7m+RCTmZnl5YAwM7O8HBBmZpaXA8LMzPJyQJiZWV4OCDMzy8sBYWZmeZV9QOzYd4jP//xpfte2M+1SzMyGlZK5UO54ZTLis/c8BcBLZ4w/Rm8zs/JR9nsQNaNGMLuumhXegzAzO0rZBwTA2TMmsKJtR9plmJkNKw4I4KXTx7N590E27TqQdilmZsOGAwI4e2Z27OHxdTvSLcTMbBhxQABnnDye0SMquG/N5rRLMTMbNhwQwKgRFbzhrGn84PGN7DvUkXY5ZmbDggMi8bbzZ7LnYAc/WrEx7VLMzIYFB0Si6ZSJzK6r5q7mdWmXYmY2LDggEpK4pmkmS9du55n2PWmXY2aWOgdEjj88bzoVGXkvwsyMAgeEpAWS1khqkXRznvn/JGl58npK0o6ceTdIejp53VDIOrtNGTeK15w+hbuXredwZ9dQfKSZ2bBVsICQVAEsBF4PzAOukzQvt09E/GVEnBMR5wD/DHwnWXYS8DHg5cB84GOSJhaq1lxva5rJlj0Hue9Jn/JqZuWtkHsQ84GWiGiNiEPAIuDKPvpfB3wzef864J6I2BYR24F7gAUFrPWIV7+kjsnVVfzQZzOZWZkrZEBMB3IP5rclbS8i6RSgAfjFQJaVdKOkZknN7e3tg1J0ZUWG15w+hfvWbPZhJjMra8NlkPpa4NsR0TmQhSLijohoioimurq6QSvm0nlT2X2gg0datw3aOs3Mik0hA2I9MDNnekbSls+1vHB4aaDLDrpXNNYxsjLD/b71hpmVsUIGxFKgUVKDpCqyIbC4ZydJpwMTgd/kNC8BLpM0MRmcvixpGxKjqyo4e+YElq71HoSZla+CBUREdAA3kf3Fvhq4KyJWSrpN0hU5Xa8FFkVE5Cy7DfgE2ZBZCtyWtA2Z+fWTeGLDLvYe9L2ZzKw8FfSRoxHxY+DHPdpu7TH98V6WvRO4s2DFHcP5DZP4l/ta+O3vd3BxY21aZZiZpWa4DFIPO+fNmkBG+DCTmZUtB0Qvxo0awey6sazc4GdVm1l5ckD04YyTa1i1YVfaZZiZpcIB0YczTq5hw84DbN97KO1SzMyGnAOiD2ecnH1W9UrvRZhZGXJA9GHetBoAj0OYWVlyQPRhYnUVU2tG8tQmP0DIzMqPA+IY5tSNpXWLA8LMyo8D4hjm1I3lmc17yLnQ28ysLDggjmF2XTW7DnSwZY/PZDKz8uKAOIY5dWMBaG33YSYzKy8OiGOYMyUbEM+07025EjOzoeWAOIZpNaMYNSLDM96DMLMy44A4hkxGzK4d60NMZlZ2HBD9MGfKWB9iMrOy44Doh9m11azbvo8Dhwf0yGwzs6LmgOiHOVPGEgHPbd2XdilmZkOmoAEhaYGkNZJaJN3cS59rJK2StFLSN3LaOyUtT14vepb1UJpTVw3ggWozKysFe+SopApgIXAp0AYslbQ4Ilbl9GkEbgEuiojtkqbkrGJ/RJxTqPoGoqE2CYjNDggzKx+F3IOYD7RERGtEHAIWAVf26PMeYGFEbAeIiM0FrOe4jamq5OTxo2jd4oFqMysfhQyI6cC6nOm2pC3XacBpkh6S9LCkBTnzRklqTtrfnO8DJN2Y9Glub28f1OJ7qq+t5lkHhJmVkbQHqSuBRuDVwHXAv0uakMw7JSKagD8Cbpc0p+fCEXFHRDRFRFNdXV1BC22orWbtVgeEmZWPQgbEemBmzvSMpC1XG7A4Ig5HxLPAU2QDg4hYn/xsBe4Hzi1grcfUUFvNjn2H2bHPN+0zs/JQyIBYCjRKapBUBVwL9Dwb6Xtk9x6QVEv2kFOrpImSRua0XwSsIkX1k7MD1T7MZGblomABEREdwE3AEmA1cFdErJR0m6Qrkm5LgK2SVgH3AX8dEVuBuUCzpMeT9k/mnv2UhvrkTCYfZjKzclGw01wBIuLHwI97tN2a8z6ADyWv3D6/Bl5ayNoGatakMWQEz/qWG2ZWJtIepC4aVZUZpk8czbO+mtrMyoQDYgDqJ1ez1mMQZlYmHBADMLs2GxB+PrWZlQMHxADU11az+2AHW/f6VFczK30OiAHoPpPJp7qaWTlwQAxAg6+FMLMy4oAYgBkTR1OZkQeqzawsOCAGoLIiw8xJY3yxnJmVBQfEANVPHsOzW3wthJmVPgfEADXUjvWprmZWFhwQA9RQO4b9hzvZtOtg2qWYmRWUA2KAfKqrmZULB8QAdd/22wPVZlbqHBADdPKE0VRVZHyqq5mVPAfEAFVkxKzJY3yIycxKngPiONRPrnZAmFnJc0Ach9l11Ty3bR9dXT7V1cxKlwPiONRPruZQRxcbdu5PuxQzs4IpaEBIWiBpjaQWSTf30ucaSaskrZT0jZz2GyQ9nbxuKGSdA1VfOwaAtb6i2sxKWMGeSS2pAlgIXAq0AUslLY6IVTl9GoFbgIsiYrukKUn7JOBjQBMQwLJk2e2FqncgGrqvhdi6l4sba1OuxsysMAq5BzEfaImI1og4BCwCruzR5z3Awu5f/BGxOWl/HXBPRGxL5t0DLChgrQMyddwoRo3I8Gy7B6rNrHQVMiCmA+typtuStlynAadJekjSw5IWDGBZJN0oqVlSc3t7+yCW3rdMRtRPrqZ1y54h+0wzs6GW9iB1JdAIvBq4Dvh3SRP6u3BE3BERTRHRVFdXV5gKe9E4dRwtmx0QZla6ChkQ64GZOdMzkrZcbcDiiDgcEc8CT5ENjP4sm6pT68ayfsd+9h3qSLsUM7OCKGRALAUaJTVIqgKuBRb36PM9snsPSKole8ipFVgCXCZpoqSJwGVJ27DROHUsEdDqcQgzK1EFC4iI6ABuIvuLfTVwV0SslHSbpCuSbkuArZJWAfcBfx0RWyNiG/AJsiGzFLgtaRs2GqeMBfBhJjMrWQU7zRUgIn4M/LhH26057wP4UPLqueydwJ2FrO9EnDK5moqMeHrz7rRLMTMriLQHqYtWVWWG+sljvAdhZiXLAXECTp0ylqcdEGZWohwQJ6Bxyjie27qPQx1daZdiZjboHBAnoHHqWDq7wk+XM7OS5IA4AXPqsmcyPb3Jh5nMrPQ4IE7AnLqxSD7V1cxKkwPiBIyuqmDGxNE85VNdzawEOSBO0Eum1rDmeQeEmZUeB8QJmjdtHK3tezhwuDPtUszMBpUD4gTNnVZDV8BTm7wXYWalxQFxguZOqwFg9cZdKVdiZja4HBAnaNakMVRXVbB6o/cgzKy0OCBOUCYjXnLSOFZ5D8LMSowDYhDMnVbD6o27yN6c1sysNDggBsHcaTXsPtDB+h370y7FzGzQOCAGwQsD1R6HMLPS4YAYBKefNA7JZzKZWWkpaEBIWiBpjaQWSTfnmf9OSe2SlievP82Z15nT3vNZ1sNK9chKTpk0xgFhZiWlYI8clVQBLAQuBdqApZIWR8SqHl2/FRE35VnF/og4p1D1DbYzpo9n+e93pF2GmdmgKeQexHygJSJaI+IQsAi4soCfl6qzZ4xn/Y79bN1zMO1SzMwGRb8CQtIHJNUo68uSHpN02TEWmw6sy5luS9p6ukrSCknfljQzp32UpGZJD0t6cy913Zj0aW5vb+/PphTMWTMmALCibWeqdZiZDZb+7kH8SUTsAi4DJgLXA58chM//AVAfEWcB9wBfyZl3SkQ0AX8E3C5pTs+FI+KOiGiKiKa6urpBKOf4nTl9PBI83rYj1TrMzAZLfwNCyc/Lga9FxMqctt6sB3L3CGYkbUdExNaI6D4m8yXgZTnz1ic/W4H7gXP7WWsqxo6s5NS6sd6DMLOS0d+AWCbpZ2QDYomkcUDXMZZZCjRKapBUBVwLHHU2kqRpOZNXAKuT9omSRibva4GLgJ6D28POWTMmsKJth6+oNrOS0N+zmN4NnAO0RsQ+SZOAd/W1QER0SLoJWAJUAHdGxEpJtwHNEbEY+AtJVwAdwDbgncnic4EvSuoiG2KfzHP207Bz9szx3P1YGxt2HmD6hNFpl2NmdkL6GxAXAssjYq+kdwDnAZ871kIR8WPgxz3abs15fwtwS57lfg28tJ+1DRtHBqrX7XBAmFnR6+8hpn8D9kk6G/gw8Azw1YJVVaTmThvHiArxuMchzKwE9DcgOiJ7YP1K4F8iYiEwrnBlFaeRlRXMnVbD8nXb0y7FzOyE9Tcgdku6hezprT+SlAFGFK6s4nXerIk8vm4nhzuPNYZvZja89Tcg3gYcJHs9xPNkT1n9TMGqKmLn109i/+FOVm7wfZnMrLj1KyCSUPg6MF7SG4EDEeExiDya6icC0Lx2W8qVmJmdmP7eauMa4FHgrcA1wCOSri5kYcVqas0oZk0aw1IHhJkVuf6e5vo3wPkRsRlAUh1wL/DtQhVWzJrqJ/LLNe1EBNKxLjg3Mxue+jsGkekOh8TWASxbdubXT2Lr3kO0btmbdilmZsetv3sQP5W0BPhmMv02elwAZy9oqp8EZMch5tSNTbkaM7Pj099B6r8G7gDOSl53RMRHCllYMZtTV83EMSNYutbXQ5hZ8er3E+Ui4m7g7gLWUjIkcX79JB5u3Zp2KWZmx63PPQhJuyXtyvPaLckn+vfholNradu+n+e2ehzCzIpTn3sQEeHbaRynixtrAXiwZQunTK5OuRozs4HzmUgFMru2mmnjR/FQy5a0SzEzOy4OiAKRxMWn1vJQy1Y6u/wAITMrPg6IArq4sZad+w+zcoNv/21mxccBUUB/MOeFcQgzs2JT0ICQtEDSGkktkm7OM/+dktolLU9ef5oz7wZJTyevGwpZZ6HUjRvJ6SeN48GnHRBmVnz6fR3EQEmqABYClwJtwFJJi/M8W/pbEXFTj2UnAR8DmoAAliXLFt2VZ696SR13Pvgsuw4cpmaUH6FhZsWjkHsQ84GWiGiNiEPAIrJPpOuP1wH3RMS2JBTuARYUqM6CunTuVA53BvevaU+7FDOzASlkQEwH1uVMtyVtPV0laYWkb0uaOcBlh71zZ01kcnUV967alHYpZmYDkvYg9Q+A+og4i+xewlcGsrCkGyU1S2pubx+e/0OvyIhL5k7hvjWb/RhSMysqhQyI9cDMnOkZSdsREbE1Ig4mk18CXtbfZZPl74iIpohoqqurG7TCB9tr505l94EOHmn1Q4TMrHgUMiCWAo2SGiRVAdcCi3M7SJqWM3kFsDp5vwS4TNJESROBy5K2ovSKxjpGjchw72ofZjKz4lGwgIiIDuAmsr/YVwN3RcRKSbdJuiLp9heSVkp6HPgL4J3JstuAT5ANmaXAbUlbURpdVcHFp9axZOXzdPmqajMrEooojV9YTU1N0dzcnHYZvfreb9fzwW8t5673Xsj8hklpl2NmBoCkZRHRlG9e2oPUZePSeVMZNSLD4sdfNJRiZjYsOSCGSPXISi6ddxI/WrHRZzOZWVFwQAyhK88+me37DvvWG2ZWFBwQQ+iVp9UxfvQIvr/ch5nMbPhzQAyhqsoMbzhrGktWbmL3gcNpl2Nm1icHxBC7pmkm+w93svjxDWmXYmbWJwfEEDt7xnhOP2kcix5dd+zOZmYpckAMMUlcN38Wv1u/kyfW+0lzZjZ8OSBS8OZzpjOyMsOipb9PuxQzs145IFIwfswILn/pNL7/2w3sOdiRdjlmZnk5IFLyxxeewu6DHdy9rC3tUszM8nJApOTcWRM5Z+YE/vPXa30DPzMblhwQKfqTixt4dste7n9qc9qlmJm9iAMiRa8/8yROqhnFlx98Nu1SzMxexAGRohEVGW74g3oeatnK79p8yquZDS8OiJS9/YJZjBtVycL7WtIuxczsKA6IlNWMGsG7/qCen658nqc27U67HDOzIxwQw8C7LmpgTFUF/+q9CDMbRgoaEJIWSFojqUXSzX30u0pSSGpKpusl7Ze0PHl9oZB1pm1idRXvuOAUFj++gZbN3osws+GhYAEhqQJYCLwemAdcJ2lenn7jgA8Aj/SY9UxEnJO83leoOoeL971qDmOqKvn0T9ekXYqZGVDYPYj5QEtEtEbEIWARcGWefp8APgUcKGAtw96k6ire+8rZ/GzVJpY9ty3tcszMChoQ04Hce1q3JW1HSDoPmBkRP8qzfIOk30r6paRX5PsASTdKapbU3N7ePmiFp+Xdr2igduxIPvWTNUT46mozS1dqg9SSMsBngQ/nmb0RmBUR5wIfAr4hqaZnp4i4IyKaIqKprq6usAUPgTFVlXzwtY08unYbv3jSV1ebWboKGRDrgZk50zOStm7jgDOB+yWtBS4AFktqioiDEbEVICKWAc8ApxWw1mHjbefPpKG2mk/99Ek6OrvSLsfMylghA2Ip0CipQVIVcC2wuHtmROyMiNqIqI+IeuBh4IqIaJZUlwxyI2k20Ai0FrDWYWNERYb/9bqX8NSmPXzjUT8vwszSU7CAiIgO4CZgCbAauCsiVkq6TdIVx1j8lcAKScuBbwPvi4iyGbldcOZJXHTqZP5xyRq27jmYdjlmVqZUKoOhTU1N0dzcnHYZg6Zl824W3P4Af3jedD599dlpl2NmJUrSsohoyjfPV1IPU6dOGce7L27gruY2Hvv99rTLMbMy5IAYxv78kkam1ozk1u8/QacfKmRmQ8wBMYyNHVnJR98wjyfW7+I/HvIzI8xsaDkghrk3njWNS06fwj/+bA2/37ov7XLMrIw4IIY5Sfz9W85kRCbDzd9Z4SuszWzIOCCKwLTxo7nl8rn8+pmtLFq67tgLmJkNAgdEkbhu/kwunD2Z//Oj1azfsT/tcsysDDggioQkPnXVWXRF8JeLlvs2HGZWcA6IIjJr8hj+/i1n8ujabfyLnz5nZgXmgCgybzl3Bm85dzqf//nTPPB08d/i3MyGLwdEEfrEm8+kcco43v/1x2ht35N2OWZWohwQRWjsyEq+dEMTlRUZ/vQrzezcdzjtksysBDkgitTMSWP44vUvY932fbz/G49x2IPWZjbIHBBF7Pz6SfzDW17Kgy1buPnu39Hl+zWZ2SCqTLsAOzHXNM1kw4793H7v00weW8X/vnxu2iWZWYlwQJSAD1zSyLa9h7jjV61Mrq7iva+ak3ZJZlYCHBAlQBIff9MZbNt7iP/7kycZU1XB9RfWp12WmRW5go5BSFogaY2kFkk399HvKkkhqSmn7ZZkuTWSXlfIOktBJiM+e805vHbuFP72+yv58oO+PbiZnZiCBYSkCmAh8HpgHnCdpHl5+o0DPgA8ktM2D7gWOANYAPxrsj7rQ1Vlhn99+8t4/Zkn8YkfruLf7n8m7ZLMrIgVcg9iPtASEa0RcQhYBFyZp98ngE8BB3LargQWRcTBiHgWaEnWZ8dQVZnhn687lzedfTKf+umTfP7nT6ddkpkVqUIGxHQg997UbUnbEZLOA2ZGxI8Gumyy/I2SmiU1t7f7thPdKisy3P62c7jqvBl89p6n+LsfrPQjS81swFIbpJaUAT4LvPN41xERdwB3ADQ1Nfk3YI6KjPjM1WcxfvQI7nzoWX6/dR+fu+5cxo70eQlm1j+F3INYD8zMmZ6RtHUbB5wJ3C9pLXABsDgZqD7WstYPmYy49U3z+MSVZ3D/U+289Qu/8bMkzKzfChkQS4FGSQ2SqsgOOi/unhkROyOiNiLqI6IeeBi4IiKak37XShopqQFoBB4tYK0l7foL67nznefTtm0fb/j8A9y/ZnPaJZlZEShYQEREB3ATsARYDdwVESsl3SbpimMsuxK4C1gF/BR4f0R0FqrWcvCq0+pY/OcXc1LNKN71n0v57M/WeFzCzPqkiNL4JdHU1BTNzc1plzHs7T/Uya3ff4L/XtbGRadO5va3nUvduJFpl2VmKZG0LCKa8s3zzfrKzOiqCj7z1rP59FVn0bx2Owtu/xX3rNqUdllmNgw5IMrUNefP5Ad/fjFTa0bxnq82c/PdK9hzsCPtssxsGHFAlLHTpo7je++/iD979Ry+1byOyz/3AMue25Z2WWY2TDggylxVZYaPLDidu957IV0RvPULv+EzS57kUIcfQGRW7hwQBmQfPvSTD7yCq182g4X3PcPln3+A+57cTKmcxGBmA+eAsCPGjRrBp68+mzvf2URnV/Cu/1zKH9/5KE8+vyvt0swsBQ4Ie5HXnD6VJR98JR970zxWtO3k8s89wC3fWcHm3QeOvbCZlQwHhOVVVZnhXRc18Mu/fjXvuqiB/25u43985n4W3tfCgcO+ZtGsHDggrE8TxlTxt2+cxz0fehUXN9bymSVreM0/3s/3l6+ny1dim5U0B4T1S0NtNV+8volvvucCJlZX8YFFy3nLv/2a5rU+LdasVDkgbEAunDOZH9x0Mf/41rN5fud+rv7Cb3jv15p5Yv3OtEszs0HmhwPYgGUy4uqXzeDyl57EHb9q5csPPsuSlZt41Wl1vO9Vc7hg9iQkpV2mmZ0g36zPTtiuA4f52m+e48sPPsu2vYdoqK3mrU0zuPq8GUypGZV2eWbWh75u1ueAsEGz/1AnP/rdRu5auo5H126jIiNe2VjLpfNO4pK5U5jqsDAbdhwQNuRa2/dwV3MbP1yxgbbt2afYnTVjPJecPpVL5k5h3rQaMhkfhjJLmwPCUhMRPLVpD/eu3sS9qzexfN0OImDimBFcMHsyZ04fz7yTazhjWg1140Z67MJsiDkgbNho332QXz3VzkPPbGHp2m2s2/bCM7Jrx1Yxd1oNc6fVMGPiaE6qGcXJE0Zz0vhRTK6ucniYFYADwoatnfsP8+TGXazauItVG7I/n960h0OdR99Ntqoyw9SakUyqHsmE0SOYOGYEE8ZUMT55Xz2ykrEjKxkzspLqqgqqR1ZSXVXJmJEVVFdVMmpExgFjlkdfAVHQ01wlLQA+B1QAX4qIT/aY/z7g/UAnsAe4MSJWSaon+xzrNUnXhyPifYWs1dIxfvQIXj57Mi+fPflIW1dXsGXvQZ7feYCNOw+wccd+Nu46wPM7D7B932F27DvEs1v2smPfIXYd6N9DjjLihcDoDo+qCkaNqGBEhRhRkcl5Ke/7ygqRkajIQEbd70UmIyokMuLI++72jMjOy2mXoKJ7mczR61SyHpHtByB1z3uhPTt809324vnZl1CyvMiul6PWcfR8ZUimddQ66bGOo9br0C1pBQsISRXAQuBSoA1YKmlxRKzK6faNiPhC0v8K4LPAgmTeMxFxTqHqs+ErkxFTxo1iyrhRnDWj774dnV3sOtDB3oMd7D3Uwd6Dnew7lEwn7/ccaeue7mDfoU72HOxg5/7DHO7sSl5x9PuOLg51dtHRFXT6tiL9ciRQjkzrqOmj+xzdWb3Mz82gXtfb2+f2Y1n1WEnPbeirpp7r7Nl/IMu+KGrV5+RRnzl3Wg3/fN25Pddwwgq5BzEfaImIVgBJi4ArgSMBERG595GuBvyv0AaksiLDpOoqJlVXFfRzOruCjq4uurqgM4KuCLqS4OiMoKsLuiI7/cLPF9q627uCo/sk/TqT9QVBBHRFdoA/gOxR4EjayOmT/efS3dbVRdI/XvgZHFlHJOsgZ71dR/WJo9YfvDCfnPldOX2ylcGRQnKmX5j/wj/rnsu8qM+L5vd/2Z5Hy49a9hjL9JxPvpr7uWzu9va2PS9epvfa883v2TBz4uiePQZFIQNiOrAuZ7oNeHnPTpLeD3wIqAJekzOrQdJvgV3ARyPigTzL3gjcCDBr1qzBq9ysh4qMqMhUpF2G2ZBK/V5MEbEwIuYAHwE+mjRvBGZFxLlkw+MbkmryLHtHRDRFRFNdXd3QFW1mVgYKGRDrgZk50zOStt4sAt4MEBEHI2Jr8n4Z8AxwWmHKNDOzfAoZEEuBRkkNkqqAa4HFuR0kNeZMvgF4OmmvSwa5kTQbaARaC1irmZn1ULAxiIjokHQTsITsaa53RsRKSbcBzRGxGLhJ0muBw8B24IZk8VcCt0k6DHQB74sIP3jAzGwI+UI5M7My1teFcqkPUpuZ2fDkgDAzs7wcEGZmllfJjEFIageeO4FV1AJbBqmctJXKtpTKdoC3ZbjytsApEZH3QrKSCYgTJam5t4GaYlMq21Iq2wHeluHK29I3H2IyM7O8HBBmZpaXA+IFd6RdwCAqlW0ple0Ab8tw5W3pg8cgzMwsL+9BmJlZXg4IMzPLq+wDQtICSWsktUi6Oe16BkrSWkm/k7RcUnPSNknSPZKeTn5OTLvOfCTdKWmzpCdy2vLWrqzPJ9/TCknnpVf5i/WyLR+XtD75bpZLujxn3i3JtqyR9Lp0qs5P0kxJ90laJWmlpA8k7UX13fSxHUX3vUgaJelRSY8n2/J3SXuDpEeSmr+V3DkbSSOT6ZZkfv1xfXD2MYLl+SJ7l9lngNlkn2j3ODAv7boGuA1rgdoebZ8Gbk7e3wx8Ku06e6n9lcB5wBPHqh24HPgJ2UfzXgA8knb9/diWjwN/lafvvOTv2kigIfk7WJH2NuTUNw04L3k/Dngqqbmovps+tqPovpfkz3Zs8n4E8EjyZ30XcG3S/gXgz5L3/xP4QvL+WuBbx/O55b4HceS52RFxiOxDi65MuabBcCXwleT9V0gexDTcRMSvgJ63ce+t9iuBr0bWw8AESdOGpNB+6GVbenMlsCiyD8Z6Fmgh+3dxWIiIjRHxWPJ+N7Ca7COEi+q76WM7ejNsv5fkz3ZPMjkieQXZxzR/O2nv+Z10f1ffBi6RpIF+brkHRL7nZvf1F2g4CuBnkpYlz+gGmBoRG5P3zwNT0yntuPRWe7F+Vzclh13uzDnUVzTbkhyaOJfs/1iL9rvpsR1QhN+LpApJy4HNwD1k93B2RERH0iW33iPbkszfCUwe6GeWe0CUgosj4jzg9cD7Jb0yd2Zk9zGL8lzmYq498W/AHOAcss9Z/3+pVjNAksYCdwMfjIhdufOK6bvJsx1F+b1ERGdEnEP28c3zgdML/ZnlHhADfW72sBMR65Ofm4Hvkv2Ls6l7Fz/5uTm9Cgest9qL7ruKiE3JP+ou4N954XDFsN8WSSPI/lL9ekR8J2kuuu8m33YU8/cCEBE7gPuAC8kezut+MmhuvUe2JZk/Htg60M8q94A45nOzhzNJ1ZLGdb8HLgOeILsN3Y9vvQH4fjoVHpfeal8M/HFyxswFwM6cwx3DUo/j8G8h+91AdluuTc40aSD7zPVHh7q+3iTHqr8MrI6Iz+bMKqrvprftKMbvRVKdpAnJ+9HApWTHVO4Drk669fxOur+rq4FfJHt9A5P26HzaL7JnYDxF9nje36RdzwBrn032rIvHgZXd9ZM91vhz4GngXmBS2rX2Uv83ye7iHyZ7/PTdvdVO9iyOhcn39DugKe36+7EtX0tqXZH8g52W0/9vkm1ZA7w+7fp7bMvFZA8frQCWJ6/Li+276WM7iu57Ac4CfpvU/ARwa9I+m2yItQD/DYxM2kcl0y3J/NnH87m+1YaZmeVV7oeYzMysFw4IMzPLywFhZmZ5OSDMzCwvB4SZmeXlgDAbBiS9WtIP067DLJcDwszM8nJAmA2ApHck9+VfLumLyQ3U9kj6p+Q+/T+XVJf0PUfSw8lN4b6b8/yEUyXdm9zb/zFJc5LVj5X0bUlPSvr68dx902wwOSDM+knSXOBtwEWRvWlaJ/B2oBpojogzgF8CH0sW+SrwkYg4i+yVu93tXwcWRsTZwB+QvQIbsncb/SDZ5xLMBi4q8CaZ9any2F3MLHEJ8DJgafKf+9Fkb1jXBXwr6fNfwHckjQcmRMQvk/avAP+d3DtrekR8FyAiDgAk63s0ItqS6eVAPfBgwbfKrBcOCLP+E/CViLjlqEbpb3v0O9771xzMed+J/31aynyIyaz/fg5cLWkKHHlG8ylk/x1131Hzj4AHI2InsF3SK5L264FfRvbJZm2S3pysY6SkMUO5EWb95f+hmPVTRKyS9FGyT/DLkL1z6/uBvcD8ZN5msuMUkL3d8heSAGgF3pW0Xw98UdJtyTreOoSbYdZvvpur2QmStCcixqZdh9lg8yEmMzPLy3sQZmaWl/cgzMwsLweEmZnl5YAwM7O8HBBmZpaXA8LMzPL6/5vY/kwpR7cLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 300\n",
    "EVAL_EVERY = 50\n",
    "\n",
    "nn_clf = train(model=nn_clf, optimizer=optimizer, criterion=criterion, epochs=EPOCHS, eval_every=EVAL_EVERY, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to make Logistic Regression, that compare it with neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_clf = LogisticRegression(penalty=\"l2\", class_weight=\"balanced\")\n",
    "def_clf.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network clf accuracy: 0.95625\n",
      "Linear clf accuracy: 0.98125\n",
      "0 class accuracy: 0.96875\n",
      "1 class accuracy: 0.03125\n",
      "\n",
      "Neural network clf report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       465\n",
      "           1       0.25      0.20      0.22        15\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.61      0.59      0.60       480\n",
      "weighted avg       0.95      0.96      0.95       480\n",
      "\n",
      "\n",
      "Logistic Regression report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       465\n",
      "           1       0.62      1.00      0.77        15\n",
      "\n",
      "    accuracy                           0.98       480\n",
      "   macro avg       0.81      0.99      0.88       480\n",
      "weighted avg       0.99      0.98      0.98       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(nn_model=nn_clf, clf=def_clf, data=test_set, labels=test_labels, report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99681\n",
       "1      319\n",
       "Name: insight, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"insight\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: ['Отлично', 'До свидания, Мария, мы вам перезвоним', 'Как ваши дела?', 'Добрый день', 'Здравствуйте, звоним вам по поводу'] - class: tensor([0, 1, 0, 0, 1])\n",
      "text: ['Отлично', 'До свидания, Мария, мы вам перезвоним', 'Как ваши дела?', 'Добрый день', 'Здравствуйте, звоним вам по поводу'] - class: [0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "text = [\n",
    "    \"Отлично\",\n",
    "    \"До свидания, Мария, мы вам перезвоним\",\n",
    "    \"Как ваши дела?\",\n",
    "    \"Добрый день\",\n",
    "    \"Здравствуйте, звоним вам по поводу\"\n",
    "]\n",
    "\n",
    "make_predict(text, rubert, tokenizer, nn_clf)\n",
    "make_predict(text, rubert, tokenizer, def_clf, neural_clf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = def_clf.predict(test_set)\n",
    "\n",
    "test_data[\"mark\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dlg_id</th>\n",
       "      <th>line_n</th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>manager</td>\n",
       "      <td>Алло здравствуйте</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>manager</td>\n",
       "      <td>Меня зовут ангелина компания диджитал бизнес з...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>manager</td>\n",
       "      <td>Да мы услышали вас спасибо за рекомендации</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>manager</td>\n",
       "      <td>Всего хорошего до свидания</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>manager</td>\n",
       "      <td>Алло здравствуйте</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>manager</td>\n",
       "      <td>Меня зовут ангелина компания диджитал бизнес з...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>manager</td>\n",
       "      <td>До свидания</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>manager</td>\n",
       "      <td>Алло здравствуйте</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>manager</td>\n",
       "      <td>Меня зовут ангелина компания диджитал бизнес з...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>manager</td>\n",
       "      <td>Алло дмитрий добрый день</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>manager</td>\n",
       "      <td>Добрый меня максим зовут компания китобизнес у...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>manager</td>\n",
       "      <td>Во вторник все ну с вами да тогда до вторника ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>manager</td>\n",
       "      <td>Все записала тогда завтра ждите звонка</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>5</td>\n",
       "      <td>142</td>\n",
       "      <td>manager</td>\n",
       "      <td>Ну до свидания хорошего вечера</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dlg_id  line_n     role  \\\n",
       "1         0       1  manager   \n",
       "3         0       3  manager   \n",
       "62        0      62  manager   \n",
       "108       0     108  manager   \n",
       "110       1       1  manager   \n",
       "111       1       2  manager   \n",
       "163       1      54  manager   \n",
       "166       2       2  manager   \n",
       "167       2       3  manager   \n",
       "250       3       1  manager   \n",
       "251       3       2  manager   \n",
       "335       4      33  manager   \n",
       "473       5     136  manager   \n",
       "479       5     142  manager   \n",
       "\n",
       "                                                  text  mark  \n",
       "1                                    Алло здравствуйте     1  \n",
       "3    Меня зовут ангелина компания диджитал бизнес з...     1  \n",
       "62          Да мы услышали вас спасибо за рекомендации     1  \n",
       "108                         Всего хорошего до свидания     1  \n",
       "110                                  Алло здравствуйте     1  \n",
       "111  Меня зовут ангелина компания диджитал бизнес з...     1  \n",
       "163                                        До свидания     1  \n",
       "166                                  Алло здравствуйте     1  \n",
       "167  Меня зовут ангелина компания диджитал бизнес з...     1  \n",
       "250                           Алло дмитрий добрый день     1  \n",
       "251  Добрый меня максим зовут компания китобизнес у...     1  \n",
       "335  Во вторник все ну с вами да тогда до вторника ...     1  \n",
       "473             Все записала тогда завтра ждите звонка     1  \n",
       "479                     Ну до свидания хорошего вечера     1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[(test_data[\"mark\"] == 1) & (test_data[\"role\"] == \"manager\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models(nn_clf, def_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_replics = test_data[(test_data[\"mark\"] == 1) & (test_data[\"role\"] == \"manager\")][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "ru_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = load_archive(\"lrl-truecaser-model-ru.tar.gz\")\n",
    "predictor = Predictor.from_archive(archive, \"truecaser-predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_replics = []\n",
    "\n",
    "for replic in extracted_replics:\n",
    "    replic = replic.title()\n",
    "    new_replic = \" \".join([morph.normal_forms(word)[0] for word in replic.split()\n",
    "              if (word not in ru_stopwords)])\n",
    "    \n",
    "    fixed_replics.append(new_replic)\n",
    "\n",
    "\n",
    "for replic in fixed_replics:\n",
    "    if replic:\n",
    "        stanza_nlp_ru(replic.title())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92d93fa2a6e32d96e7dac402f34597514116f09396a20e0d5cf5fef27c1e0f34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
